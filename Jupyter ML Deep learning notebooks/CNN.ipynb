{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils as u\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "#Lets start by loading the Cifar10 data\n",
    "(X, y), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#Keep in mind the images are in RGB\n",
    "#So we can normalise the data by diving by 255\n",
    "#The data is in integers therefore we need to convert them to float first\n",
    "X, X_test = X.astype('float32')/255.0, X_test.astype('float32')/255.0\n",
    "\n",
    "#Then we convert the y values into one-hot vectors\n",
    "#The cifar10 has only 10 classes, thats is why we specify a one-hot\n",
    "#vector of width/class 10\n",
    "y, y_test = u.to_categorical(y, 10), u.to_categorical(y_test, 10)\n",
    "\n",
    "#Now we can go ahead and create our Convolution model\n",
    "model = Sequential()\n",
    "#We want to output 32 features maps. The kernel size is going to be\n",
    "#3x3 and we specify our input shape to be 32x32 with 3 channels\n",
    "#Padding=same means we want the same dimensional output as input\n",
    "#activation specifies the activation function\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same',\n",
    "                 activation='relu'))\n",
    "#20% of the nodes are set to 0\n",
    "model.add(Dropout(0.2))\n",
    "#now we add another convolution layer, again with a 3x3 kernel\n",
    "#This time our padding=valid this means that the output dimension can\n",
    "#take any form\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='valid'))\n",
    "#maxpool with a kernet of 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#In a convolution NN, we neet to flatten our data before we can\n",
    "#input it into the ouput/dense layer\n",
    "model.add(Flatten())\n",
    "#Dense layer with 512 hidden units\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#this time we set 30% of the nodes to 0 to minimize overfitting\n",
    "model.add(Dropout(0.3))\n",
    "#Finally the output dense layer with 10 hidden units corresponding to\n",
    "#our 10 classe\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#Few simple configurations\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(momentum=0.5, decay=0.0004), metrics=['accuracy'])\n",
    "#Run the algorithm!\n",
    "model.fit(X, y, validation_data=(X_test, y_test), epochs=25,\n",
    "          batch_size=512)\n",
    "#Save the weights to use for later\n",
    "model.save_weights(\"cifar10.hdf5\")\n",
    "#Finally print the accuracy of our model!\n",
    "print(\"Accuracy: &2.f%%\" %(model.evaluate(X_test, y_test)[1]*100))\n",
    "#print(model.predict_classes(X[0:1]))\n",
    "#Prints out a number\n",
    "#1 - airplane, 2 - automobile, 3 - bird, 4 - cat, 5 - deer, 6 - dog\n",
    "#7 - frog, 8 - horse, 9 - ship, 10 - truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
